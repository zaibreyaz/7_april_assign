{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d018e619-4fc4-4086-84d1-bfc3413f44a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?\\n\\n    Ans: Polynomial functions can be used as kernel functions to implicitly map input data into a higher-dimensional feature space in machine learning algorithms.          This allows linear algorithms to be applied to non-linear problems, which can be computationally efficient, especially for high-dimensional feature spaces.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?\n",
    "\n",
    "    Ans: Polynomial functions can be used as kernel functions to implicitly map input data into a higher-dimensional feature space in machine learning algorithms. \\\n",
    "         This allows linear algorithms to be applied to non-linear problems, which can be computationally efficient, especially for high-dimensional feature spaces.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462e7578-61b1-4f6e-bee0-2ff71f3fc1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\"\"\"\n",
    "\n",
    "# from sklearn.svm import SVC\n",
    "# classifier = SVC(kernel='ploy', degree=3)\n",
    "# classifier.fit(X_train, y_train)\n",
    "# y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1ca3008-132b-4837-849b-7e3902dd3e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\\n\\n    Ans: Increasing the value of epsilon in Support Vector Regression (SVR) leads to an increase in the number of support vectors. This is because larger values of epsilon allow \\n         more data points to be within the margin of tolerance, resulting in a larger margin and more support vectors required to define it.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
    "\n",
    "    Ans: Increasing the value of epsilon in Support Vector Regression (SVR) leads to an increase in the number of support vectors. This is because larger values of epsilon allow \n",
    "         more data points to be within the margin of tolerance, resulting in a larger margin and more support vectors required to define it.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6e79c24-702b-479d-9ea3-ef22584f8972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? \\nCan you explain how each parameter works and provide examples of when you might want to increase or decrease its value?\\n\\n    Ans: 1. Kernel function: The choice of kernel function determines how the input data is mapped to a higher-dimensional feature space. Common kernel functions include linear, \\n                polynomial, and radial basis function (RBF). If the data is linearly separable, a linear kernel can be used. If the data is non-linear, a polynomial or \\n                RBF kernel may be more appropriate. The choice of kernel function should be based on the characteristics of the data.\\n         2. C parameter: The C parameter controls the trade-off between the model's complexity and its ability to fit the training data. A large value of C allows the model to \\n                fit the training data more closely, but may lead to overfitting. A small value of C results in a simpler model but may underfit the data. The value of C should \\n                be chosen based on the size of the training data and the desired level of generalization.\\n         3. Epsilon parameter: The epsilon parameter controls the size of the margin of tolerance around the predicted values. A larger value of epsilon allows more data points \\n                to be within the margin of tolerance, resulting in a larger margin and more support vectors required to define it. A smaller value of epsilon leads to a smaller \\n                margin and fewer support vectors. The choice of epsilon should be based on the desired level of tolerance around the predicted values.\\n         4. Gamma parameter: The gamma parameter controls the influence of each training example. A small value of gamma means that each training example has a large influence,\\n                resulting in a smoother decision boundary. A large value of gamma means that each training example has a smaller influence, resulting in a more complex decision\\n                boundary. The choice of gamma should be based on the size of the dataset and the desired level of generalization.\\n\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? \n",
    "Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?\n",
    "\n",
    "    Ans: 1. Kernel function: The choice of kernel function determines how the input data is mapped to a higher-dimensional feature space. Common kernel functions include linear, \n",
    "                polynomial, and radial basis function (RBF). If the data is linearly separable, a linear kernel can be used. If the data is non-linear, a polynomial or \n",
    "                RBF kernel may be more appropriate. The choice of kernel function should be based on the characteristics of the data.\n",
    "         2. C parameter: The C parameter controls the trade-off between the model's complexity and its ability to fit the training data. A large value of C allows the model to \n",
    "                fit the training data more closely, but may lead to overfitting. A small value of C results in a simpler model but may underfit the data. The value of C should \n",
    "                be chosen based on the size of the training data and the desired level of generalization.\n",
    "         3. Epsilon parameter: The epsilon parameter controls the size of the margin of tolerance around the predicted values. A larger value of epsilon allows more data points \n",
    "                to be within the margin of tolerance, resulting in a larger margin and more support vectors required to define it. A smaller value of epsilon leads to a smaller \n",
    "                margin and fewer support vectors. The choice of epsilon should be based on the desired level of tolerance around the predicted values.\n",
    "         4. Gamma parameter: The gamma parameter controls the influence of each training example. A small value of gamma means that each training example has a large influence,\n",
    "                resulting in a smoother decision boundary. A large value of gamma means that each training example has a smaller influence, resulting in a more complex decision\n",
    "                boundary. The choice of gamma should be based on the size of the dataset and the desired level of generalization.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "422a3d8a-e6de-4c22-bb14-a3926e4b4a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q5. Assignment:\\nL Import the necessary libraries and load the dataset\\nL Split the dataset into training and testing sets\\nL Preprocess the data using any technique of your choice (e.g. scaling, normalimation)\\nL Create an instance of the SVC classifier and train it on the training data\\nL Use the trained classifier to predict the labels of the testing data\\nL Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\\nprecision, recall, F1-scoreK\\nL Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\\nimprove its performance\\nL Train the tuned classifier on the entire dataset\\nL Save the trained classifier to a file for future use.\\n\\nYou can use any dataset of your choice for this assignment, but make sure it is suitable for\\nclassification and has a sufficient number of features and samples.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Q5. Assignment:\n",
    "L Import the necessary libraries and load the dataset\n",
    "L Split the dataset into training and testing sets\n",
    "L Preprocess the data using any technique of your choice (e.g. scaling, normalimation)\n",
    "L Create an instance of the SVC classifier and train it on the training data\n",
    "L Use the trained classifier to predict the labels of the testing data\n",
    "L Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
    "precision, recall, F1-scoreK\n",
    "L Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
    "improve its performance\n",
    "L Train the tuned classifier on the entire dataset\n",
    "L Save the trained classifier to a file for future use.\n",
    "\n",
    "You can use any dataset of your choice for this assignment, but make sure it is suitable for\n",
    "classification and has a sufficient number of features and samples.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f32b6c-7819-430a-b965-8e03962dbe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64382131-450f-48e2-a0a9-aa99c52d5a37",
   "metadata": {},
   "source": [
    "# we are using Diamond Dataset to Classify Cut type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd745c1a-6d46-4a71-84cb-dc729ca580a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = sns.load_dataset('diamonds')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9650f183-be96-4423-979a-ca872ad2f271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53940 entries, 0 to 53939\n",
      "Data columns (total 10 columns):\n",
      " #   Column   Non-Null Count  Dtype   \n",
      "---  ------   --------------  -----   \n",
      " 0   carat    53940 non-null  float64 \n",
      " 1   cut      53940 non-null  category\n",
      " 2   color    53940 non-null  category\n",
      " 3   clarity  53940 non-null  category\n",
      " 4   depth    53940 non-null  float64 \n",
      " 5   table    53940 non-null  float64 \n",
      " 6   price    53940 non-null  int64   \n",
      " 7   x        53940 non-null  float64 \n",
      " 8   y        53940 non-null  float64 \n",
      " 9   z        53940 non-null  float64 \n",
      "dtypes: category(3), float64(6), int64(1)\n",
      "memory usage: 3.0 MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "794cfcfc-5661-42f8-9d05-de67c2b2d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "## create an instance of OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "# fitting the encoder to the dataframe and transforming the categorical variable\n",
    "encoded = encoder.fit_transform(dataset[['color','clarity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "475f298e-57bf-44e5-a6ab-31847f133d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = pd.DataFrame(encoded.toarray() , columns = encoder.get_feature_names_out())\n",
    "data = pd.concat([dataset, en_df], axis = 1)\n",
    "data.drop('color',axis=1,inplace=True)\n",
    "data.drop('clarity',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb76deb-dc14-4011-b98c-f451a848b8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>color_D</th>\n",
       "      <th>color_E</th>\n",
       "      <th>...</th>\n",
       "      <th>color_I</th>\n",
       "      <th>color_J</th>\n",
       "      <th>clarity_I1</th>\n",
       "      <th>clarity_IF</th>\n",
       "      <th>clarity_SI1</th>\n",
       "      <th>clarity_SI2</th>\n",
       "      <th>clarity_VS1</th>\n",
       "      <th>clarity_VS2</th>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <th>clarity_VVS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut  depth  table  price     x     y     z  color_D  color_E  \\\n",
       "0   0.23    Ideal   61.5   55.0    326  3.95  3.98  2.43      0.0      1.0   \n",
       "1   0.21  Premium   59.8   61.0    326  3.89  3.84  2.31      0.0      1.0   \n",
       "2   0.23     Good   56.9   65.0    327  4.05  4.07  2.31      0.0      1.0   \n",
       "3   0.29  Premium   62.4   58.0    334  4.20  4.23  2.63      0.0      0.0   \n",
       "4   0.31     Good   63.3   58.0    335  4.34  4.35  2.75      0.0      0.0   \n",
       "\n",
       "   ...  color_I  color_J  clarity_I1  clarity_IF  clarity_SI1  clarity_SI2  \\\n",
       "0  ...      0.0      0.0         0.0         0.0          0.0          1.0   \n",
       "1  ...      0.0      0.0         0.0         0.0          1.0          0.0   \n",
       "2  ...      0.0      0.0         0.0         0.0          0.0          0.0   \n",
       "3  ...      1.0      0.0         0.0         0.0          0.0          0.0   \n",
       "4  ...      0.0      1.0         0.0         0.0          0.0          1.0   \n",
       "\n",
       "   clarity_VS1  clarity_VS2  clarity_VVS1  clarity_VVS2  \n",
       "0          0.0          0.0           0.0           0.0  \n",
       "1          0.0          0.0           0.0           0.0  \n",
       "2          1.0          0.0           0.0           0.0  \n",
       "3          0.0          1.0           0.0           0.0  \n",
       "4          0.0          0.0           0.0           0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f02e8a3-3f39-4c60-91bf-fbd7625e7bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['carat', 'depth', 'table', 'price', 'x', 'y', 'z', 'color_D', 'color_E', 'color_F', 'color_G', 'color_H', 'color_I', 'color_J', \n",
    "                 'clarity_I1', 'clarity_IF', 'clarity_SI1', 'clarity_SI2', 'clarity_VS1', 'clarity_VS2', 'clarity_VVS1', 'clarity_VVS2']\n",
    "target = 'cut'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "536dd3e7-b871-44cf-b7bb-34c01048a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[features_list]\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "775f2790-42d3-489a-a05e-a25b842dcc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fb0f930-0d1a-409c-9405-830ed9f26773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standard Scaling - Standardization\n",
    "def standard_scaler(X_train, X_test):\n",
    "#     scaling the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "#     Saving the model as pickle file\n",
    "    file = open('scaler.pkl','wb')\n",
    "    pickle.dump(scaler, file)\n",
    "    file.close()\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "X_train_scaled, X_test_scaled = standard_scaler(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35c3dfc6-ad95-4f35-adfe-6078f1717926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC()\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "y_p = classifier.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d8fd84f-c78a-49ce-a49a-6751b08697dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Very Good' 'Ideal' 'Very Good' ... 'Ideal' 'Ideal' 'Ideal']\n"
     ]
    }
   ],
   "source": [
    "print(y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "772202cc-6249-4988-82fc-c15e8645f482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7153009516747003\n",
      "[[ 343   91    4   11    2]\n",
      " [  44  788   46  172  442]\n",
      " [   4    7 5971  306  178]\n",
      " [   2   40  505 3357  266]\n",
      " [   2  254 1014 1217 1116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fair       0.87      0.76      0.81       451\n",
      "        Good       0.67      0.53      0.59      1492\n",
      "       Ideal       0.79      0.92      0.85      6466\n",
      "     Premium       0.66      0.81      0.73      4170\n",
      "   Very Good       0.56      0.31      0.40      3603\n",
      "\n",
      "    accuracy                           0.72     16182\n",
      "   macro avg       0.71      0.67      0.68     16182\n",
      "weighted avg       0.70      0.72      0.69     16182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(accuracy_score(y_test, y_p))\n",
    "print(confusion_matrix(y_test, y_p))\n",
    "print(classification_report(y_test, y_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e529f1c-a5cf-4527-b681-26a729befa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "p = {\n",
    "    'C':[0.1,1,10,100,1000],\n",
    "    'gamma':[1,0.1,0.01,0.001,0.0001],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(SVC(), param_distributions=p, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725cad3-1536-41e7-86eb-90ea6e3f6593",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.680 total time= 1.2min\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.675 total time= 1.3min\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.675 total time= 1.3min\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.683 total time= 1.3min\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.680 total time= 1.3min\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6001b6-4077-4f6c-80f7-b5704bd9d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.best_estimator_)\n",
    "y_p2 = clf.predict(X_test_scaled)\n",
    "print(accuracy_score(y_test, y_p2))\n",
    "print(confusion_matrix(y_test, y_p2))\n",
    "print(classification_report(y_test, y_p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a9079f-1ed5-4086-b76c-8601f20f547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = StandardScaler()\n",
    "X_scaled =  s.fit_transform(X)\n",
    "file = open('Entire_dataset_scaler.pkl','wb')\n",
    "pickle.dump(s, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dfc4a6-fbea-402f-9b3c-0353aa2dff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC()\n",
    "classifier.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d0d905-583e-4120-b44c-4621ca789857",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(classifier, open('SVC.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb1015-3d10-49ac-b3a3-689caf808931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0ab9f7-4ed2-4949-b3a1-888a54919cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
